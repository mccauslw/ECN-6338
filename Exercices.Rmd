---
title: "Exercices, ECN 6338, Hiver 2022"
author: "William McCausland"
date: "`r Sys.Date()`"
output: pdf_document
---

## Cours 1. Introduction

### Exercices théorique

1. Montrez que $6n^2 + 3n + 10 = O(n^2)$.

### Exercices de computation

1. Lisez l'aide sur la fonction \texttt{expm1} et démontrez son avantage par rapport à la fonction \texttt{exp} pour évaluer $e^x - 1$ quand $|x|$ est prés de zéro.
Vous pouvez suivre l'exemple sur \texttt{log1p} dans les diapos.

1. Téléchargez le paquet R \texttt{microbenchmark}, lisez l'aide sur la fonction \texttt{microbenchmark} et mesurer le temps nécessaire pour faire les opérations \texttt{x * y}, \texttt{x / y}, \texttt{exp(y)} et \texttt{log(x)}, pour un vecteur $x > 0$ de mille éléments et un vecteur $y$ de mille éléments.

\pagebreak

## Cours 2. La résolution de systèmes d'équations linéaires

### Exercices préliminaires

1. Soit $L_1$ et $L_2$ des matrices triangulaires inférieures $n\times n$.
Soit $U_1$ et $U_2$ des matrices triangulaires supérieures $n\times n$.
Supposez que $L_1$ et $U_1$ sont inversibles.
    a. Parmi les matrices suivantes, lequelles sont toujours triangulaires inférieures :
    $L_1L_2$, $L_1+L_2$, $L_1^{-1}$, $L_1^\top$, $U_1^\top$, $L_1U_1$?
    a. Parmi les matrices suivantes, lequelles sont toujours triangulaires supérieures :
    $U_1U_2$, $U_1+U_2$, $U_1^{-1}$, $U_1^\top$, $L_1^\top$, $L_1U_1$?
    
1. (Substitution avant et substitution arrière)
Soit $L$ et $U$ des matrices inversibles $n \times n$, où $L$ est triangulaire inférieure et $U$ est triangulaire supérieure.
Soit $y$ un vecteur $n \times 1$.
Notez que Judd utilise le terme "back substitution" pour décrire deux algorithmes distincts (a. et b.).
Plusieurs auteurs font une distinction entre "back substitution" (b.) et "forward substitution" (a.).
    a. Trouver un algorithme pour résoudre l'équation $Lx = y$.
    Notez que $L_{11} x_1 = y_1$, alors $x_1 = y_1/L_{11}$.
    a. Trouvez un algorithme pour résoudre l'équation $Ux = y$.
    Commencez par $x_n$.

1. Soit $x$ un $n$-vecteur aléatoire avec moyenne $\mu$ ($n\times 1$) et variance $\Sigma$ ($n \times n$). Soit $A$ une matrice constante $m \times n$.
Quelles sont la moyenne et la variance de $Ax$?

### Exercices théoriques

1. Quelquefois, il est plus facile de spécifier la matrice de précision $H = \Sigma^{-1}$ que la matrice de variance $\Sigma$, pour une loi gaussienne multivariée $N(\mu,\Sigma)$.
Si vous avez la matrice $H$ et non la matrice $\Sigma$, décrivez comment on peut tirer des variables aléatoires $N(\mu,\Sigma)$ et évaluer la densité gaussienne multivariée.
Commencez par la décomposition cholesky de $H$.

1. La matrice de précision $H$ pour un processus AR(1) gaussien est
tridiagonale ($H_{ij} = 0$ pour $|i-j|>1$) et symmétrique. Si $\omega = \sigma^{-2}$ est la précision de l'innovation et $\phi$ est le coefficient d'autorégression, le diagonal de $H$ est $\omega(1,1+\phi^2,\ldots,1+\phi^2,1)$ et le sous-diagonal est $-\omega(\phi, \ldots, \phi)$.
Trouvez la décomposition cholesky de $H$, en utilisant une description de l'algorithme (page 59 de Judd, par exemple).

1. Dans l'exemple MCO, calculez le vecteur $e = y - Xb$ des résiduelles et $\hat{\sigma}^2 (X^\top X)^{-1}$, une estimation de la variance de $b$. Utilisez seulement $y$ et la décomposition QR de $X$, pas $X$ elle-même. Notez que $\hat{\sigma}^2 = e^\top e/(n-k)$.

1. Donnez la matrice creuse des diapos en format colonne compressée après les deux opérations suivantes. Décrivez brièvement les algorithmes pour l'insertion et la supression en général.
    a. Une insertion \texttt{A[2,4] <- 24},
    a. Une supression \texttt{A[3,2] <- 0}.

### Exercices de computation

1. Regardez la démonstration \texttt{GPA.R} (au site Github du cours) de l'analyse d'une régression linéaire, exemple 3.1 dans Wooldridge (2016) Introductory Econometrics.
Calculez $b$, $e$ et $\hat{\sigma}^2 (X^\top X)^{-1}$ en utilisant la décomposition QR.
La fonction \texttt{qr} effectue la décomposition QR, les fonctions \texttt{qr.Q} et \texttt{qr.R} extraient les matrices $Q_1$ et $R_1$ du résultat.
Les fonctions \texttt{backsolve} et \texttt{t} (transpose) pourraient être utiles.

\pagebreak

## Cours 3. Quelques sujets préalables

### Exercices préliminaires

1. Trouvez le panier de consommation $(x_1^*,x_2^*)$ qui maximise $U(x_1,x_2) = x_1^{1/2} x_2^{1/2}$ sous les contraintes $p_1x_1 + p_2x_2 = m$, $x_1 \geq 0$ et $x_2 \geq 0$, où $m > 0$, $p_1 > 0$ et $p_2 > 0$.
Utilisez la méthode de Lagrange.

1. Si $X_i|\lambda \sim \mathrm{iid}\;\mathrm{Exp}(\lambda)$ (loi exponentielle) et $\lambda \sim \mathrm{Ga}(\alpha, \beta)$ (loi gamma)
écrivez
    a. la fonction de densité conditionnelle de $(X_1,\ldots,X_n)$ sachant $\lambda$.
    a. la densité conjointe de $(X_1,\ldots,X_n)$ et $\lambda$.

### Exercices théoriques

1. Considérez l'exercice préliminaire 1, avec la contrainte remplacée par $(p_1x_1 + p_2x_2 - m)^3 = 0$.
La solution du problème doit être pareille.
Décrivez le problème qui se présente quand vous essayez d'utiliser la méthode de Lagrange.
Expliquez brièvement pourquoi ce problème ne représente pas une contradiction du théorème de Lagrange.

1. Pour le modèle de l'exercice préliminaire 2,
    a. trouvez l'estimateur maximum de vraisemblance $\hat\lambda$ de $\lambda$; trouvez la moyenne et la variance de $\hat\lambda^{-1}$. (La moyenne et la variance de $\hat\lambda$ n'ont pas d'expression simple.)
    a. trouvez la distribution postérieure $\lambda|x^\circ$, où $x^\circ$ est une réalisation de $(X_1,\ldots,X_n)$.

### Exercices de computation

Aucune, étant donnée la nature du cours 3.

\pagebreak

## Cours 4. L'optimisation statique

### Exercice préliminaire

1. Lisez la section "Newton's Method" pp 96-97 dans Judd.
1. Prenez la fonction de log vraisemblance (graphique, diapo 19, cours 3) $L(\theta;y) = n_1 \log \theta + n_0 \log (1-\theta)$, pour $n_0 = 200$ et $n_1 = 230$.
    a. Calculez l'expansion Taylor d'ordre deux (quadratique) de $L(\theta;y)$ autour de $\theta = 1/2$.
    a. Trouvez la valeur de $\theta$ qui maximise cette fonction quadratique.
    a. Considerez le même problème que a., mais pour la vraisemblance ${\cal L}(\theta;y) = \theta^{n_1} (1-\theta)^{n_0}$.
    Faites assez de ce problème pour vous convaincre que c'est plus difficile.

### Exercices théoriques

1. On veut modeler le choix binaire $y_i \in \{0,1\}$ d'une individu $i$ comme fonction du vecteur $x_i \in \mathbb{R}^k$ des variables explicatives, pour un échantillon aléatoire $\{(y_i, x_i)\}$, $i=1,\ldots,n$.
Le modèle probit donne la probabilité conditionnelle $\Pr[y_i|x_i]$ comme $\Pr[y_i|x_i] = \Phi(x_i^\top \beta)$ où $\beta \in \mathbb{R}^k$ et $\Phi$ est la fonction de répartition d'une variable aléatoire gaussienne standard (\texttt{pnorm} en R; sa dérivée de première ordre est la densité, \texttt{dnorm} en R).
    a. Écrivez la fonction de log vraisemblance $L(\beta;y, X)$,
    où $y = (y_1,\ldots,y_n)$ est $X$ et la matrice $n \times k$ de variables explicatives.
    a. Donnez le gradient et la matrice hessienne de $L(\beta;y, X)$.
    Montrez que la matrice hessienne est négative définie.

### Exercices de computation

L'exercice est de reproduire les résultats du modèle probit de l'exemple 17.1 de Wooldridge, qui concerne le choix des femmes mariées d'être dans la population active ou non.
Vous pouvez charger les données avec
```{r mroz}
library(wooldridge)
data(mroz, package='wooldridge')
```
et ensuite voir les statistiques sommaires avec \texttt{summary(mroz)}.

1. Écrivez des fonctions en R pour calculer la valeur, le gradient et la matrice hessienne de la fonction de log vraisemblance $L(\beta;y, X)$ du modèle probit.
1. Trouvez l'estimation maximum de vraisemblance $\hat\beta$ pour le modèle probit de l'exemple 17.1 de Wooldridge, avec les méthodes Nelder-Mead et BFGS.
Les variables sont une constante,
\texttt{nwifeinc}, \texttt{educ}, \texttt{exper}, \texttt{exper} carré, \texttt{age}, \texttt{kidslt6}, \texttt{kidsge6}.
1. Calculer moins la matrice hessienne de la log vraisemblance au point $\hat\beta$.
Calculer l'inverse de cette matrice et donnez les écarts-types asymptotiques des éléments de $\hat\beta$ (les racines carrées des éléments diagonaux).



\pagebreak

## Cours 5. La résolution de systèmes d'équations non-linéaires

### Exercices préliminaires

1. Considérez le problème de trouver une racine de la fonction $f(x) = e^x - x - 2$ dans l'intervalle $[0,2]$. Faites avec une calculatrice :
    a. trois cycles de l'algorithme 5.1 (bisection).
    a. trois cycles de l'algorithme 5.2 (Newton).
