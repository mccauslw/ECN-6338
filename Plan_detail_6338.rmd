---
title: "Plan de cours détaillé pour ECN 6338: Analyse numérique en économie"
author: "William McCausland"
date: "19/10/2021"
output: pdf_document
urlcolor: blue
---

# Documents

### Documents obligatoires

Manuel principal

- Judd (1998), "Numerical Methods in Economics"

Livres gratuits (fournis par les auteurs) supplémentaires

- Devroye (1986), "Non-Uniform Random Number Generation"
- Train (2009), "Discrete Choice Methods with Simulation", 2e édition

Papiers scientifiques

- Geweke and Durham (2019), "Sequentially adaptive Bayesian learning algorithms for inference and optimization"
- Creal (2012), "A Survey of Sequential Monte Carlo Methods for Economics and Finance"

Autres documents

- Diverses pages Wikipédia
- Notes et diapositives du professeur

### Documents recommandés sur les matières prélalables

- Avinash K. Dixit (1990), "Optimization in Economic Theory" (2e édition)
- Ljungqvist and Sargent (2018), "Recursive Macroeconomic Theory" (4e édition)

### Autres documents et sites internet

- Site web [QuantEcon](https://quantecon.org)
- Site Github du cours [CompEcon2020](https://github.com/KennethJudd/CompEcon2020) de Judd

# Évaluation

Les éléments de l'évaluation sont

1. Environ dix interrogations de dix minutes (20\%)
1. Quatre exercices de computation (40\%)
1. Un projet de computation (15\%)
1. Un examen final (25\%)

# Matière organisée par cours

## Cours 1. Introduction

### Matières

1. Dérivées multivariées, vecteur gradient, matrices jacobienne et hessienne
1. Analyse des erreurs numériques
1. Analyse (de la complexité) d'algorithmes
1. Parallélisme

### Lectures

1. Judd, Chapitres 1 et 2
1. Page Wikipédia sur [l'algorithme de Strassen](https://fr.wikipedia.org/wiki/Algorithme_de_Strassen)
1. Page Wikipédia sur la représentation des nombres [virgules flottantes](https://en.wikipedia.org/wiki/Floating-point_arithmetic)
1. Page Wikipédia sur [le calcul différentiel matriciel](https://en.wikipedia.org/wiki/Matrix_calculus).
Notez que le cours suit la convention "numerator layout".




## Cours 2. La résolution de systèmes d'équations linéaires

### Matières

1. Décompositions $LU$, $QR$ et Cholesky d'une matrice
1. Méthodes directes pour la résolution de systèmes linéaires
1. Méthodes itératives pour la résolution de systèmes linéaires
1. Applications
    a. calcul de l'équilibre : offre et demande, jeux Cournot, jeux Bertrand
    a. calcul de l'estimation MCO
    a. génération de variables aléatoires gaussiennes multivariées, évaluation de leur densité

### Lectures

1. Judd: 3.1, 3.2, 3.4, 3.6, 3.7, 3.8, 3.9
1. Page Wikipédia sur la [décomposition QR](https://en.wikipedia.org/wiki/QR_decomposition). Il y a une courte section sur l'applications aux problèmes MCO, "Using for solution to linear inverse problems".
1. Page Wikipédia sur les [matrices creuses](https://en.wikipedia.org/wiki/Sparse_matrix)
1. Page Wikipédia sur les [matrices orthogonaux](https://en.wikipedia.org/wiki/Orthogonal_matrix)
1. Notes du professeur sur la génération de variables aléatoires gaussiennes multivariées




## Cours 3. Quelques sujets préalables

### Matières

1. Optimisation sous contraintes, conditions de Karush-Kuhn-Tucker
1. Maximum de vraisemblance
1. Inférence bayésienne
1. Applications : (cas simples où les méthodes numériques ne sont pas nécessaires)
    a. un problème de consommateur avec préférences quasi-linéaires, où une solution de coin est possibles
    a. un problème d'allocation de ressources, où le chomage des ressources est possible.
    a. analyse maximum de vraisemblance d'un modèle poissonien de comptes de transactions
    a. analyse bayésienne du même modèle 

### Lectures

1. Notes du professeur basées sur les exemples 3.1 "Quasi-linear Preferences" et 3.1 "Technological Unemployment" de Dixit (1990).
1. Page Wikipédia sur l'[estimation maximum de vraisemblance](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation), Sections "Principles", "Properties" et "Examples"
1. Page Wikipédia sur l'[inférence bayésienne](https://en.wikipedia.org/wiki/Bayesian_inference), Sections "Introduction to Bayes' Rule" and "Formal Description of Bayesian Inference".
1. Documents du professeur sur l'estimation maximum de vraisemblance et l'estimation bayésienne (en anglais).




## Cours 4. L'optimisation statique

### Matières

1. Problèmes unidimensionnels
1. Méthodes de comparaison
1. Méthode de Newton et ses raffinements
1. Applications:
    a. problème d'un monopole qui maximise son profit.
    a. maximisation de vraisemblance pour un modèle logit

### Lectures

1. Judd: 4.1, 4.2, 4.3, 4.4
1. Page Wikipédia sur la méthode [Nelder-Mead](https://en.wikipedia.org/wiki/Nelder–Mead_method)
1. Page Wikipédia sur la méthode [BFGS](https://en.wikipedia.org/wiki/Broyden–Fletcher–Goldfarb–Shanno_algorithm)




## Cours 5. La résolution de systèmes d'équations non-linéaires

### Matières

1. La résolution d'équations univariées
    a. la méthode de dichotomie
    a. la méthode de Newton, la convergence, des règles d'arrêt
1. La résolution de systèmes d'équation
    a. itération Gauss-Seidel
    a. itération point fixe (pas fait, 2022)
    a. les méthodes de Newton et Broydon
1. Application: la computation d'équilibre d'oligopole

### Lectures

1. Judd: 5.1, 5.2, 5.3, 5.4, 5.5




## Cours 6. L'approximation de fonctions

### Matières

1. Approximation locale, développement de Taylor, approximant de Padé
1. Suites de polynômes orthogonaux, approximation des moindres carrés
1. Approximation uniforme
1. Interpolation
1. Interpolation par morceaux, splines
1. Application : approximation de la courbe des contrats dans une économie à deux personnes et deux biens

### Lectures

1. Judd: 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.8, 6.9




## Cours 7. L'intégration et la dérivation (méthodes déterministes)

### Matières

1. Newton-Cotes
1. La quadrature unidimensionnelle et multidimensionnelle
1. Dérivation numérique
1. Dérivation automatique
1. Application : évaluation d'utilité actualisée en temps continu


### Lectures

1. Judd: 7.1, 7.2, 7.3, 7.5, 7.6, 7.7
1. Page Wikipédia sur [la dérivation automatique](https://fr.wikipedia.org/wiki/Dérivation_automatique)




## Cours 8. La génération de variables aléatoires univariées

### Matières

1. La génération de nombres pseudo-aléatoires et le Mersenne Twister
1. La génération de variables aléatoires non-uniformes
    a. méthode de l'inverse de la fonction de répartition (avec exemple Weibull)
    a. méthode de rejet (avec exemple gamma)
    a. l'algorithme Ziggurat (avec exemple gaussien)
1. Les nombres quasi-aléatoires et les suites à discrépance faible
1. La génération directe faisable de quelques variables aléatoires multivariées (gaussiennes, dirichlet, wishart)
1. Application : intégration stochastique dans l'exemple de l'évaluation d'utilité actualisée en temps continu

### Lectures

1. Judd: 8.1, 8.2, 8.3
1. Page Wikipédia sur le [Mersenne Twister](https://en.wikipedia.org/wiki/Mersenne_Twister)
1. Page Wikipédia sur l'algorithme [Ziggurat](https://en.wikipedia.org/wiki/Ziggurat_algorithm)
1. Devroye II.2 and II.3 (méthode de l'inverse de la fonction de répartition, méthode de rejet)
1. Page Wikipédia sur la [méthode de rejet](https://en.wikipedia.org/wiki/Rejection_sampling),
Sections "Description", "Theory" et "Algorithm"





## Cours 9. La génération de variables aléatoires multivariées

### Matières

1. L'échantillonnage préférentiel (importance sampling)
1. L'algorithme Metropolis-Hastings
1. L'échantillonnage de Gibbs
1. Applications :
    a. simulation postérieure pour un modèle probit de choix discret
    a. maximum de vraisemblance simulée pour un modèle mixed-logit de choix discret

### Lectures

1. Judd: 8.1, 8.2, 8.3, 8.4, 8.5
1. Page Wikipédia sur l'[échantillonage préférentiel](https://en.wikipedia.org/wiki/Importance_sampling), Sections "Basic Theory" et "Application to Simulation"
1. Page Wikipédia sur l'algorithme [Metropolis-Hastings](https://en.wikipedia.org/wiki/Metropolis–Hastings_algorithm),
Sections "Intuition" et "Formal Derivation"
1. Page Wikipédia sur l'[échantillonage de Gibbs](https://en.wikipedia.org/wiki/Gibbs_sampling), Section "Implementation"
1. Train: chapitres 5, 6, 10




## Cours 10. La simulation Monte Carlo séquentielle

### Matières

1. La simulation Monte Carlo séquentielle 
1. Familles d'algorithmes reliées
    a. le recuit simulé (simulated annealing)
    a. le filtre particulaire (particle filter)
1. Applications
    a. maximum de vraisemblance pour un modèle EGARCH avec un vraisemblance autrement infaisable
    a. inférence bayésienne pour le même modèle

### Lectures

1. Geweke et Durham (2019)
1. Creal (2012)
1. Judd: 8.3, section "Simulated Annealing"




## Cours 11. La résolution des équations différentielles

### Matières

1. Équations différentielles avec conditions au bord
1. La résolution de systèmes d'équations différentielles linéaires
1. Les méthodes du type Runge-Kutta pour les équations différentielles non-linéaires
1. Applications :
    a. Calcul de l'équilibre d'un modèle de signalisation de Spence
    a. Problèmes de commande optimale (optimal control) dans un modèle "cycle de vie" avec consommation et offre de travail

### Lectures

1. Judd: 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7




## Cours 12 et 13. La programmation dynamique

### Matières

1. Le problème canonique de programmation en temps discret
1. Le problème canonique de programmation en temps continu
1. Problèmes avec horizon fini, problèmes avec horizon infini
1. Problèmes avec transitions déterministes, problèmes avec transitions stochastiques
1. Problèmes avec espace-état fini
1. Itération de la fonction de valeur
1. Itération de la fonction de politique
1. Discrétisation de problèmes avec espace-état continu
1. Application : problèmes d'accumulation stochastiques

### Lectures

1. Judd: 12.1, 12.2, 12.3, 12.4, 12.5


